{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Food_Safery_Amazon_Word2Vec.ipynb\t",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1FoBa1rx-Kgy1mvYHahJjKXb1TjoS0Zql",
      "authorship_tag": "ABX9TyOeq9R/vfhOc0W4YrLCWKS1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solharsh/Company_Project_Food_Safety/blob/master/Food_Safery_Amazon_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFNwXMWfg7or",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1affbcbf-7cf5-4412-f2f5-e50672216c0a"
      },
      "source": [
        "! pip install xgboost"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ7z1aV_g_9M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "64fd785f-dd65-4ba1-c9f7-d1f6acd95292"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 108kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.4)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RPz-7oqhA1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "0e6f2f60-8b02-45d9-d9a0-59340cc9b6a3"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.23.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.15.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (2.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNq_WR8OhB3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "28f1180e-20ec-4eed-e6a0-444089f1c44d"
      },
      "source": [
        "!pip install vaderSentiment"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JvxPDU7hCnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\t\n",
        "import lightgbm as lgb\t\n",
        "import catboost\t\n",
        "import pandas as pd\t\n",
        "import numpy as np\t\n",
        "from sklearn.model_selection import train_test_split\t\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import re\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aAt4bbjhIlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "e745d75d-5eb8-4e12-ce07-f20f09038f6c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\t\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFpo05nuhOL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.remove('off')\t\n",
        "stop_words.add('amazon')\t\n",
        "stop_words.add('product')\t\n",
        "stop_words.add('info')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjAHBgi4hR2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lmtzr = WordNetLemmatizer()\n",
        "tokenizer = RegexpTokenizer(r'\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irXnKPeHhU6x",
        "colab_type": "text"
      },
      "source": [
        "# Prepare training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2hgk5r7hTY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Food_Safety_Amazon/training.csv', sep=None, header=0, index_col=False, parse_dates=['Timestamp'],engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxNOQAeNhdS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "d8e34120-bc01-4899-f7c1-672f85ffeb66"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Product ASIN</th>\n",
              "      <th>Review star rating</th>\n",
              "      <th>Food Safety Issue</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>@nlp.sentenceCount</th>\n",
              "      <th>@product.brand</th>\n",
              "      <th>@product.countryOfOrigin</th>\n",
              "      <th>Product Width</th>\n",
              "      <th>Product Length</th>\n",
              "      <th>Product Height</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Product Title (Analyzed)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024</td>\n",
              "      <td>B004DSMGXE</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Very stale!  Went into garbage....</td>\n",
              "      <td>Went into garbage..</td>\n",
              "      <td>3</td>\n",
              "      <td>Ferrara</td>\n",
              "      <td>MX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-10-29 09:43:00</td>\n",
              "      <td>Wrapped Vanilla Caramel Squares 2lb, 2 Pound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4208</td>\n",
              "      <td>B003XDM33I</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>I always use raw cashews in my smoothies and a...</td>\n",
              "      <td>... raw cashews in my smoothies and as these t...</td>\n",
              "      <td>2</td>\n",
              "      <td>Sunfood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2017-12-20 00:18:00</td>\n",
              "      <td>Sunfood Cashews, Whole, 1lb, Organic, Raw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3373</td>\n",
              "      <td>B01H4B1DB2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>I am super pissed off. I can�t return this? Pr...</td>\n",
              "      <td>I am super pissed off</td>\n",
              "      <td>6</td>\n",
              "      <td>Forever Green</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-01-15 03:21:00</td>\n",
              "      <td>Paradise Green Uncrystallized Dried Ginger Sli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3388</td>\n",
              "      <td>B00JJY30R8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>These are so hard and stale you can break a to...</td>\n",
              "      <td>Inedible Marpo Marshmallow Candy Cones</td>\n",
              "      <td>2</td>\n",
              "      <td>Marpro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-03-28 01:09:00</td>\n",
              "      <td>Marpro Yum Yum Marshmallow Candy Cones - 30 Ct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5004</td>\n",
              "      <td>B003RLNOYS</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>I love larabars. What I don�t love, and what e...</td>\n",
              "      <td>Moldy, smelly, disgusting in the last 2 orders</td>\n",
              "      <td>5</td>\n",
              "      <td>L�RABAR</td>\n",
              "      <td>US</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2017-11-30 18:40:00</td>\n",
              "      <td>Larabar Gluten Free Bar, Chocolate Chip Cookie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ID  ...                           Product Title (Analyzed)\n",
              "0  2024  ...       Wrapped Vanilla Caramel Squares 2lb, 2 Pound\n",
              "1  4208  ...          Sunfood Cashews, Whole, 1lb, Organic, Raw\n",
              "2  3373  ...  Paradise Green Uncrystallized Dried Ginger Sli...\n",
              "3  3388  ...  Marpro Yum Yum Marshmallow Candy Cones - 30 Ct...\n",
              "4  5004  ...  Larabar Gluten Free Bar, Chocolate Chip Cookie...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct_PytNChef2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "0e6c90eb-4c9d-44c5-b8fe-cffdf4e894a0"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Product ASIN', 'Review star rating', 'Food Safety Issue',\n",
              "       'Review Text', 'Review Title', '@nlp.sentenceCount', '@product.brand',\n",
              "       '@product.countryOfOrigin', 'Product Width', 'Product Length',\n",
              "       'Product Height', 'Timestamp', 'Product Title (Analyzed)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAHOlXQDhfPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "bf42bc6b-c434-412f-fc7a-1aa0a84151a9"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Review star rating</th>\n",
              "      <th>Food Safety Issue</th>\n",
              "      <th>@nlp.sentenceCount</th>\n",
              "      <th>Product Width</th>\n",
              "      <th>Product Length</th>\n",
              "      <th>Product Height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3769.000000</td>\n",
              "      <td>3769.000000</td>\n",
              "      <td>3769.000000</td>\n",
              "      <td>3769.000000</td>\n",
              "      <td>1469.000000</td>\n",
              "      <td>1469.000000</td>\n",
              "      <td>1469.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2691.956487</td>\n",
              "      <td>1.472008</td>\n",
              "      <td>0.864155</td>\n",
              "      <td>4.715309</td>\n",
              "      <td>4.973349</td>\n",
              "      <td>6.718455</td>\n",
              "      <td>5.675956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1554.811470</td>\n",
              "      <td>0.778782</td>\n",
              "      <td>0.342669</td>\n",
              "      <td>4.082598</td>\n",
              "      <td>3.001311</td>\n",
              "      <td>4.314668</td>\n",
              "      <td>3.741902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1340.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2716.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4024.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5384.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                ID  Review star rating  ...  Product Length  Product Height\n",
              "count  3769.000000         3769.000000  ...     1469.000000     1469.000000\n",
              "mean   2691.956487            1.472008  ...        6.718455        5.675956\n",
              "std    1554.811470            0.778782  ...        4.314668        3.741902\n",
              "min       1.000000            1.000000  ...        0.000000        0.000000\n",
              "25%    1340.000000            1.000000  ...        3.500000        3.000000\n",
              "50%    2716.000000            1.000000  ...        6.000000        5.500000\n",
              "75%    4024.000000            2.000000  ...        9.000000        7.870000\n",
              "max    5384.000000            5.000000  ...       84.000000       84.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR1B8r9Whgqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "27b2ecbe-b93f-4160-da38-d59a644e8f39"
      },
      "source": [
        "df.isnull().sum(axis=0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                             0\n",
              "Product ASIN                   0\n",
              "Review star rating             0\n",
              "Food Safety Issue              0\n",
              "Review Text                    0\n",
              "Review Title                   0\n",
              "@nlp.sentenceCount             0\n",
              "@product.brand                79\n",
              "@product.countryOfOrigin    2801\n",
              "Product Width               2300\n",
              "Product Length              2300\n",
              "Product Height              2300\n",
              "Timestamp                      0\n",
              "Product Title (Analyzed)       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9sSBUHAhhj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f364c4a5-1e09-4db4-97c2-9bc3af39737e"
      },
      "source": [
        "df['Food Safety Issue'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3257\n",
              "0     512\n",
              "Name: Food Safety Issue, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7-SdVYIhkDL",
        "colab_type": "text"
      },
      "source": [
        "# Define feature engineering functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GcvRYrchiXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(s):\n",
        "    if isinstance(s, str):\n",
        "        s = re.sub(r'[^a-zA-Z\\s]', '', s, re.I|re.A)\n",
        "        s = str(s).lower()\n",
        "        word_list = tokenizer.tokenize(s)\n",
        "        word_list = [word for word in word_list if not word in stop_words]\n",
        "        word_list = [lmtzr.lemmatize(word) for word in word_list]\n",
        "        return word_list\n",
        "    return []\n",
        "\t\n",
        "def word_vector(s):\n",
        "\t  word_list = preprocess(s)\n",
        "\t  return np.mean([words[x].values for x in word_list if x in words],axis=0)\n",
        "\t\n",
        "\t\n",
        "def get_sentiment_scores_of_sentence(sentence):\n",
        "  word_list = preprocess(sentence)\n",
        "  sentimentAnalyser = SentimentIntensityAnalyzer()\n",
        "  sentimentScores = sentimentAnalyser.polarity_scores(' '.join(word_list))\n",
        "  return sentimentScores\n",
        "\t\n",
        "def get_sentiment_scores_of_column(df, columnName):\t\n",
        "    sentimentScoresHeader = [columnName+'_neg', columnName+'_neu', columnName+'_pos', columnName+'_compound']\n",
        "    sentimentScoresDf = pd.DataFrame(np.nan, index=[], columns=sentimentScoresHeader)\n",
        "    isOverallNeg = []\n",
        "    for i in range(df.shape[0]): #range(10, 21):\n",
        "        sentence = df.loc[i, columnName]\n",
        "        if isinstance(sentence, str):\n",
        "            curScores = get_sentiment_scores_of_sentence(sentence)\n",
        "            curScoresDf = pd.DataFrame.from_dict(dict([ [sentimentScoresHeader[0], [curScores.get('neg')]],\n",
        "                                                        [sentimentScoresHeader[1], [curScores.get('neu')]],\n",
        "                                                        [sentimentScoresHeader[2], [curScores.get('pos')]],\n",
        "                                                        [sentimentScoresHeader[3], [curScores.get('compound')]] ]), orient='columns')\n",
        "        else:\n",
        "            curScoresDf = pd.DataFrame.from_dict(dict([ [sentimentScoresHeader[0], [0.0]],\n",
        "                                                        [sentimentScoresHeader[1], [0.0]],\n",
        "                                                        [sentimentScoresHeader[2], [0.0]],\n",
        "                                                        [sentimentScoresHeader[3], [0.0]] ]), orient='columns')\n",
        "        sentimentScoresDf = sentimentScoresDf.append(curScoresDf, ignore_index=True)\n",
        "\t\n",
        "        if (curScores.get('neg') > curScores.get('pos')):\n",
        "            isOverallNeg.append(1)\n",
        "        else:\n",
        "            isOverallNeg.append(0)\n",
        "    return sentimentScoresDf, isOverallNeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMYmvQbhiNZX",
        "colab_type": "text"
      },
      "source": [
        "# Add sentiment score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "milLUtCkh9Rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TextSentimentScores, TextIsOverallNeg = get_sentiment_scores_of_column(df, 'Review Text')\n",
        "TitleSentimentScores, TitleIsOverallNeg = get_sentiment_scores_of_column(df, 'Review Title')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1VoS6mliRci",
        "colab_type": "text"
      },
      "source": [
        "# Add missing value indicator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v04ZaRV1iPus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['missingorigin'] = df['@product.countryOfOrigin'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
        "df['Product Width'].fillna(-1, inplace=True)\n",
        "df['Product Height'].fillna(-1, inplace=True)\n",
        "df['Product Length'].fillna(-1, inplace=True)\n",
        "df['missingwd'] = df.apply(lambda x: 1 if x['Product Width']+x['Product Length']+x['Product Height']==-1 else 0, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESwC9jw6iVo7",
        "colab_type": "text"
      },
      "source": [
        "# Add other features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvfW9OVbiUdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['timezero'] = pd.Timestamp('20170101')\n",
        "df['timedif'] = (df['Timestamp'] - df['timezero']).apply(lambda x: x.days)\n",
        "#df['timedif'].head(5)\n",
        "df['volumn'] = df['Product Width'] * df['Product Length'] * df['Product Height']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkMl24ZLiZwP",
        "colab_type": "text"
      },
      "source": [
        "# add review text word2vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AlutRKyiYUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5b36922b-ce01-479e-ef4d-d1e404954066"
      },
      "source": [
        "#!git clone https://github.com/mmihaltz/word2vec-GoogleNews-vectors.git"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'word2vec-GoogleNews-vectors' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkdMEjq7j5rU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4f2a5e9e-e5d5-4507-f6d8-074f031e2613"
      },
      "source": [
        "#import gensim.downloader as api\n",
        "#wv = api.load('word2vec-google-news-300')\n",
        "#vec_king = wv['king']"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 98.5% 1637.2/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxDR5-_xn8mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = pd.read_table(\"https://www.dropbox.com/s/flh1fjynqvdsj4p/lexvec.commoncrawl.300d.W.pos.vectors.gz?dl=1\", compression=\"gzip\", encoding=\"utf-8\", sep=\" \", index_col=0, header=None, skiprows=[0]).transpose()\n",
        "#words = pd.read_table(\"/content/word2vec-GoogleNews-vectors/GoogleNews-vectors-negative300.bin.gz\", compression=\"gzip\", encoding=\"utf-8\", sep=\" \", index_col=0, header=None, skiprows=[0]).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMtZS5ookVgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text2vec'] = df['Review Text'].apply(word_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccCVmatLlo0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8f244542-29b3-4729-a936-d7dfe7998a83"
      },
      "source": [
        "reviewarray = np.zeros((len(df), 300))\n",
        "for i in range(len(df)):\n",
        "    reviewarray[i, :] = df['text2vec'][i]\n",
        "reviewarray.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3769, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcElUjJKlpxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\t\n",
        "similarity_matrix = cosine_similarity(reviewarray)\n",
        "Z = linkage(similarity_matrix, 'ward')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9LJ60Zqlsfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "4643c4f3-9a4b-4186-c954-79b98405ce85"
      },
      "source": [
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Data point')\n",
        "plt.ylabel('Distance')\n",
        "dendrogram(Z)\n",
        "plt.axhline(y=1.0, c='k', ls='--', lw=0.5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f4bf579ae48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSDjOIdvluu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "efbb9237-c690-4ee1-b1df-3902d0d3c920"
      },
      "source": [
        "from scipy.cluster.hierarchy import fcluster\n",
        "max_dist = 250.\n",
        "cluster_labels = fcluster(Z, max_dist, criterion='distance')\n",
        "w2vlabels = pd.DataFrame(cluster_labels, columns=['clusterlabelw2v'])\n",
        "catdf = pd.concat([df, w2vlabels ], axis=1)\n",
        "print(len(catdf[(catdf['Food Safety Issue']==0) & (catdf.clusterlabelw2v==1)]))\n",
        "print(len(catdf[(catdf['Food Safety Issue']==0) & (catdf.clusterlabelw2v==2)]))\n",
        "print(len(catdf[(catdf['Food Safety Issue']==1) & (catdf.clusterlabelw2v==1)]))\n",
        "print(len(catdf[(catdf['Food Safety Issue']==1) & (catdf.clusterlabelw2v==2)]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "335\n",
            "177\n",
            "1715\n",
            "1542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj8YnRNBlyN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_split = df['text2vec'].apply(lambda x: pd.Series([x[i] for i in range(300)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyeSc44zlzVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_split.rename(columns={i:'text' + str(i+1) for i in range(300)},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrT5ffoNl0Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.concat([df, w2vlabels, text_split], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS-nV_All2LU",
        "colab_type": "text"
      },
      "source": [
        "# add review title word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wag_0l3Dl0uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "260cfd00-0d37-49f1-d21f-a846f5d56719"
      },
      "source": [
        "df1['title2vec'] = df1['Review Title'].apply(word_vector)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7fxZEm-l3da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_split = df1['title2vec'].apply(lambda x: pd.Series([x[i] if not isinstance(x,np.float64) else np.nan for i in range(300)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRzrFo-hl4IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_split.rename(columns={i:'title' + str(i+1) for i in range(300)},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEEYgjKel41c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.concat([df1, title_split], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrE91O6Fl5iE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "eea0ca51-885d-4f0d-ff10-85bcb2a36cff"
      },
      "source": [
        "df['timedif'].groupby(df['Food Safety Issue']).median()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Food Safety Issue\n",
              "0    326\n",
              "1    330\n",
              "Name: timedif, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl1hTbwPl6S_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "925b848a-32dc-49bb-9010-6848af93a9a5"
      },
      "source": [
        "df['volumn'].groupby(df['Food Safety Issue']).median()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Food Safety Issue\n",
              "0   -1.0\n",
              "1   -1.0\n",
              "Name: volumn, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM4Q5elul8Kj",
        "colab_type": "text"
      },
      "source": [
        "# add bag-of-words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUR75oa0l7Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(s):\n",
        "    s = re.sub(r'[^a-zA-Z\\s]', '', s, re.I|re.A)\n",
        "    s = str(s).lower()\n",
        "    word_list = tokenizer.tokenize(s)\n",
        "    word_list = [word for word in word_list if not word in stop_words]\n",
        "    word_list = [lmtzr.lemmatize(word) for word in word_list]\n",
        "    return ' '.join(word_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVkXPg2hl_FL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b1b31cdc-1d85-4873-f5a7-eb6d2f37233c"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(min_df=0., max_df=1.)\n",
        "cv_matrix = cv.fit_transform(df2['Review Text'].apply(clean))\n",
        "cv_matrix = cv_matrix.toarray()\n",
        "cv_matrix.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3769, 8653)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apj6_LNgmBSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = cv.get_feature_names()\n",
        "bow = pd.DataFrame(cv_matrix, columns=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daJxhqOcmDuk",
        "colab_type": "text"
      },
      "source": [
        "# add n-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNKoAVdRmCjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bv = CountVectorizer(ngram_range=(2,2))\n",
        "bv_matrix = bv.fit_transform(df2['Review Text'].apply(clean))\n",
        "bv_matrix = bv_matrix.toarray()\n",
        "vocab = bv.get_feature_names()\n",
        "bigram = pd.DataFrame(bv_matrix, columns=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADvXCG_ymG11",
        "colab_type": "text"
      },
      "source": [
        "# add tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_WTTLh9mF74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
        "tv_matrix = tv.fit_transform(df2['Review Text'].apply(clean))\n",
        "tv_matrix = tv_matrix.toarray()\n",
        "vocab = tv.get_feature_names()\n",
        "tfidf = pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sig7UhqmLmS",
        "colab_type": "text"
      },
      "source": [
        "#tf-idf cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kixh20c7mKkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "4bb6c60c-0d3a-4d0a-8695-2bd87ab9c7a3"
      },
      "source": [
        "similarity_matrix = cosine_similarity(tv_matrix)\n",
        "similarity_df = pd.DataFrame(similarity_matrix)\n",
        "similarity_df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>3729</th>\n",
              "      <th>3730</th>\n",
              "      <th>3731</th>\n",
              "      <th>3732</th>\n",
              "      <th>3733</th>\n",
              "      <th>3734</th>\n",
              "      <th>3735</th>\n",
              "      <th>3736</th>\n",
              "      <th>3737</th>\n",
              "      <th>3738</th>\n",
              "      <th>3739</th>\n",
              "      <th>3740</th>\n",
              "      <th>3741</th>\n",
              "      <th>3742</th>\n",
              "      <th>3743</th>\n",
              "      <th>3744</th>\n",
              "      <th>3745</th>\n",
              "      <th>3746</th>\n",
              "      <th>3747</th>\n",
              "      <th>3748</th>\n",
              "      <th>3749</th>\n",
              "      <th>3750</th>\n",
              "      <th>3751</th>\n",
              "      <th>3752</th>\n",
              "      <th>3753</th>\n",
              "      <th>3754</th>\n",
              "      <th>3755</th>\n",
              "      <th>3756</th>\n",
              "      <th>3757</th>\n",
              "      <th>3758</th>\n",
              "      <th>3759</th>\n",
              "      <th>3760</th>\n",
              "      <th>3761</th>\n",
              "      <th>3762</th>\n",
              "      <th>3763</th>\n",
              "      <th>3764</th>\n",
              "      <th>3765</th>\n",
              "      <th>3766</th>\n",
              "      <th>3767</th>\n",
              "      <th>3768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025378</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036895</td>\n",
              "      <td>0.075386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028618</td>\n",
              "      <td>0.020092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030672</td>\n",
              "      <td>0.033027</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024360</td>\n",
              "      <td>0.023824</td>\n",
              "      <td>0.036154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133837</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086361</td>\n",
              "      <td>0.036521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038339</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044494</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034680</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089879</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271559</td>\n",
              "      <td>0.027907</td>\n",
              "      <td>0.027925</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046378</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025238</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046995</td>\n",
              "      <td>0.013822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030268</td>\n",
              "      <td>0.014723</td>\n",
              "      <td>0.056258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041220</td>\n",
              "      <td>0.066877</td>\n",
              "      <td>0.009469</td>\n",
              "      <td>0.012225</td>\n",
              "      <td>0.065225</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021954</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032914</td>\n",
              "      <td>0.015177</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055279</td>\n",
              "      <td>0.016215</td>\n",
              "      <td>0.063918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012674</td>\n",
              "      <td>0.024753</td>\n",
              "      <td>0.010514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051507</td>\n",
              "      <td>0.052469</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013992</td>\n",
              "      <td>0.058869</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022663</td>\n",
              "      <td>0.087273</td>\n",
              "      <td>0.014740</td>\n",
              "      <td>0.053614</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013160</td>\n",
              "      <td>0.036163</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042744</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024345</td>\n",
              "      <td>0.056884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.114552</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024404</td>\n",
              "      <td>0.045650</td>\n",
              "      <td>0.032163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018686</td>\n",
              "      <td>0.022094</td>\n",
              "      <td>0.038428</td>\n",
              "      <td>0.037889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010214</td>\n",
              "      <td>0.044447</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015233</td>\n",
              "      <td>0.034026</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039574</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017876</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.173475</td>\n",
              "      <td>0.017743</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045711</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042237</td>\n",
              "      <td>0.026988</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067350</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068122</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.025378</td>\n",
              "      <td>0.025238</td>\n",
              "      <td>0.114552</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027788</td>\n",
              "      <td>0.057636</td>\n",
              "      <td>0.044986</td>\n",
              "      <td>0.011375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012697</td>\n",
              "      <td>0.025943</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011730</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009849</td>\n",
              "      <td>0.006914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043787</td>\n",
              "      <td>0.011366</td>\n",
              "      <td>0.038650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008383</td>\n",
              "      <td>0.008199</td>\n",
              "      <td>0.055790</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046059</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029720</td>\n",
              "      <td>0.056355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013194</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015312</td>\n",
              "      <td>0.017459</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026651</td>\n",
              "      <td>0.004682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011935</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030931</td>\n",
              "      <td>0.041251</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056284</td>\n",
              "      <td>0.036715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093454</td>\n",
              "      <td>0.039840</td>\n",
              "      <td>0.009610</td>\n",
              "      <td>0.030583</td>\n",
              "      <td>0.022897</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071567</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.156748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034516</td>\n",
              "      <td>0.050764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010538</td>\n",
              "      <td>0.112708</td>\n",
              "      <td>0.015507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140053</td>\n",
              "      <td>0.027943</td>\n",
              "      <td>0.025875</td>\n",
              "      <td>0.126389</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.058458</td>\n",
              "      <td>0.026087</td>\n",
              "      <td>0.018882</td>\n",
              "      <td>0.011934</td>\n",
              "      <td>0.014783</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016962</td>\n",
              "      <td>0.040310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056524</td>\n",
              "      <td>0.029596</td>\n",
              "      <td>0.050096</td>\n",
              "      <td>0.010958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119648</td>\n",
              "      <td>0.010130</td>\n",
              "      <td>0.018710</td>\n",
              "      <td>0.042519</td>\n",
              "      <td>0.008931</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.009166</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114169</td>\n",
              "      <td>0.019236</td>\n",
              "      <td>0.027221</td>\n",
              "      <td>0.042531</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072962</td>\n",
              "      <td>0.008171</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045699</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021359</td>\n",
              "      <td>0.022291</td>\n",
              "      <td>0.017926</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052962</td>\n",
              "      <td>0.051536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3764</th>\n",
              "      <td>0.046378</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071567</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023203</td>\n",
              "      <td>0.047410</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021436</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017998</td>\n",
              "      <td>0.012636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019289</td>\n",
              "      <td>0.020771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015320</td>\n",
              "      <td>0.014983</td>\n",
              "      <td>0.101954</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084170</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054312</td>\n",
              "      <td>0.102987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018441</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.170784</td>\n",
              "      <td>0.017551</td>\n",
              "      <td>0.017562</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041844</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3765</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042744</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031401</td>\n",
              "      <td>0.106941</td>\n",
              "      <td>0.029991</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032078</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037635</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075944</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056143</td>\n",
              "      <td>0.053195</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033605</td>\n",
              "      <td>0.046345</td>\n",
              "      <td>0.041488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.036101</td>\n",
              "      <td>0.013205</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151956</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030331</td>\n",
              "      <td>0.033429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3766</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.015846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041409</td>\n",
              "      <td>0.170250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063926</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020510</td>\n",
              "      <td>0.028730</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031816</td>\n",
              "      <td>0.064480</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022550</td>\n",
              "      <td>0.077379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086584</td>\n",
              "      <td>0.020958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065326</td>\n",
              "      <td>0.136042</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066007</td>\n",
              "      <td>0.160302</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027296</td>\n",
              "      <td>0.024266</td>\n",
              "      <td>0.073322</td>\n",
              "      <td>0.012168</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024224</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014190</td>\n",
              "      <td>0.022614</td>\n",
              "      <td>0.056081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3767</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084667</td>\n",
              "      <td>0.011772</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006184</td>\n",
              "      <td>0.061776</td>\n",
              "      <td>0.021066</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006936</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016374</td>\n",
              "      <td>0.005663</td>\n",
              "      <td>0.042279</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024159</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118952</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026557</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032553</td>\n",
              "      <td>0.027108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014809</td>\n",
              "      <td>0.031379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025869</td>\n",
              "      <td>0.071758</td>\n",
              "      <td>0.013449</td>\n",
              "      <td>0.048247</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.092766</td>\n",
              "      <td>0.057892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025911</td>\n",
              "      <td>0.032207</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030947</td>\n",
              "      <td>0.007871</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3768</th>\n",
              "      <td>0.016310</td>\n",
              "      <td>0.056884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005613</td>\n",
              "      <td>0.018612</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054796</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041697</td>\n",
              "      <td>0.010604</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.077003</td>\n",
              "      <td>0.008160</td>\n",
              "      <td>0.059700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050715</td>\n",
              "      <td>0.007539</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046737</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.071489</td>\n",
              "      <td>0.006784</td>\n",
              "      <td>0.007305</td>\n",
              "      <td>0.062564</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005388</td>\n",
              "      <td>0.005269</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029601</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019100</td>\n",
              "      <td>0.008077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.089973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033328</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120887</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003009</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013167</td>\n",
              "      <td>0.019725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008781</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.060060</td>\n",
              "      <td>0.154671</td>\n",
              "      <td>0.024002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014715</td>\n",
              "      <td>0.115588</td>\n",
              "      <td>0.010257</td>\n",
              "      <td>0.033429</td>\n",
              "      <td>0.036834</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3769 rows × 3769 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2     ...      3766      3767      3768\n",
              "0     1.000000  0.000000  0.000000  ...  0.000000  0.000000  0.016310\n",
              "1     0.000000  1.000000  0.000000  ...  0.000000  0.024345  0.056884\n",
              "2     0.000000  0.000000  1.000000  ...  0.000000  0.000000  0.000000\n",
              "3     0.025378  0.025238  0.114552  ...  0.000000  0.000000  0.005613\n",
              "4     0.000000  0.000000  0.000000  ...  0.051536  0.000000  0.018612\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "3764  0.046378  0.000000  0.000000  ...  0.000000  0.000000  0.010257\n",
              "3765  0.000000  0.042744  0.000000  ...  0.000000  0.030331  0.033429\n",
              "3766  0.000000  0.000000  0.000000  ...  1.000000  0.000000  0.036834\n",
              "3767  0.000000  0.024345  0.000000  ...  0.000000  1.000000  0.000000\n",
              "3768  0.016310  0.056884  0.000000  ...  0.036834  0.000000  1.000000\n",
              "\n",
              "[3769 rows x 3769 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6cTEA_MmNqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "62df106d-59a7-412d-876d-0800a1008289"
      },
      "source": [
        "Z = linkage(similarity_matrix, 'ward')\n",
        "pd.DataFrame(Z, columns=['Document\\Cluster 1', 'Document\\Cluster 2', 'Distance', 'Cluster Size'], dtype='object')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document\\Cluster 1</th>\n",
              "      <th>Document\\Cluster 2</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Cluster Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>810</td>\n",
              "      <td>2091</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>490</td>\n",
              "      <td>2584</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68</td>\n",
              "      <td>2496</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2344</td>\n",
              "      <td>2564</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "      <td>1162</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3763</th>\n",
              "      <td>7527</td>\n",
              "      <td>7531</td>\n",
              "      <td>23.1005</td>\n",
              "      <td>2450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3764</th>\n",
              "      <td>7498</td>\n",
              "      <td>7532</td>\n",
              "      <td>30.0156</td>\n",
              "      <td>2586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3765</th>\n",
              "      <td>7524</td>\n",
              "      <td>7530</td>\n",
              "      <td>47.6067</td>\n",
              "      <td>1130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3766</th>\n",
              "      <td>7533</td>\n",
              "      <td>7534</td>\n",
              "      <td>70.6721</td>\n",
              "      <td>3716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3767</th>\n",
              "      <td>3898</td>\n",
              "      <td>7535</td>\n",
              "      <td>95.4491</td>\n",
              "      <td>3769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3768 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Document\\Cluster 1 Document\\Cluster 2 Distance Cluster Size\n",
              "0                   810               2091        0            2\n",
              "1                   490               2584        0            2\n",
              "2                    68               2496        0            2\n",
              "3                  2344               2564        0            2\n",
              "4                    39               1162        0            2\n",
              "...                 ...                ...      ...          ...\n",
              "3763               7527               7531  23.1005         2450\n",
              "3764               7498               7532  30.0156         2586\n",
              "3765               7524               7530  47.6067         1130\n",
              "3766               7533               7534  70.6721         3716\n",
              "3767               3898               7535  95.4491         3769\n",
              "\n",
              "[3768 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbL4cdFjmQs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "0868d92a-37c3-4dd9-c7b1-87036a8c044f"
      },
      "source": [
        "plt.figure(figsize=(8, 3))\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Data point')\n",
        "plt.ylabel('Distance')\n",
        "dendrogram(Z)\n",
        "plt.axhline(y=1.0, c='k', ls='--', lw=0.5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f495fea3ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6SuhArN3GJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_dist = 80.\n",
        "cluster_labels = fcluster(Z, max_dist, criterion='distance')\n",
        "tfidflabels = pd.DataFrame(cluster_labels, columns=['clusterlabeltfidf'])\n",
        "#pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPdEq-uQ3IvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "0ae1a533-d578-46e2-b659-1320cc2154af"
      },
      "source": [
        "catdf = pd.concat([df, tfidflabels], axis=1)\n",
        "print(len(catdf[(catdf['Food Safety Issue']==0) & (catdf.clusterlabeltfidf==1)]))\n",
        "print(len(catdf[(catdf['Food Safety Issue']==0) & (catdf.clusterlabeltfidf==2)]))\n",
        "print(len(catdf[(catdf['Food Safety Issue']==1) & (catdf.clusterlabeltfidf==1)]))\n",
        "print(len(catdf[(catdf['Food Safety Issue']==1) & (catdf.clusterlabeltfidf==2)]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "510\n",
            "51\n",
            "3206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ClYZik33MBN",
        "colab_type": "text"
      },
      "source": [
        "#add LDA (too slow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtCBDcQZ3KgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.decomposition import LatentDirichletAllocation\n",
        "#lda = LatentDirichletAllocation(n_topics=2, max_iter=10000, random_state=0) \n",
        "#dt_matrix = lda.fit_transform(cv_matrix) \n",
        "#features = pd.DataFrame(dt_matrix, columns=['T1', 'T2']) \n",
        "#catdf_lda = pd.concat([df, features], axis=1) \n",
        "#rint(catdf_lda['T1'].groupby('Food Safety Issue').mean()) \n",
        "#print(catdf_lda['T2'].groupby('Food Safety Issue').mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsms0p083XAy",
        "colab_type": "text"
      },
      "source": [
        "#training, test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouH0ymTJ3UzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df2['Food Safety Issue']\n",
        "X = df2.drop(['ID','Product ASIN','Food Safety Issue','Review Text', 'Review Title', '@product.brand','@product.countryOfOrigin', 'Timestamp', 'Product Title (Analyzed)','text2vec','title2vec','timezero'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cuQ99Jh3ZaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2vec_fts = ['text' + str(i+1) for i in range(300)]\n",
        "title2vec_fts = ['title' + str(i+1) for i in range(300)]\n",
        "prod2vec_fts = ['e' + str(i+1) for i in range(128)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9NPooFe3cqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.concat([X, tfidflabels], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln4WF8Eg3di_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "e18e8590-1a97-4d53-80c3-5d6a0c551a24"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Review star rating', '@nlp.sentenceCount', 'Product Width',\n",
              "       'Product Length', 'Product Height', 'missingorigin', 'missingwd',\n",
              "       'timedif', 'volumn', 'clusterlabelw2v',\n",
              "       ...\n",
              "       'title292', 'title293', 'title294', 'title295', 'title296', 'title297',\n",
              "       'title298', 'title299', 'title300', 'clusterlabeltfidf'],\n",
              "      dtype='object', length=611)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlDBbXSA3eSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X['clusterlabelw2v'] = X['clusterlabelw2v'].apply(lambda x: 1 if x ==1 else 0)\n",
        "X['clusterlabeltfidf'] = X['clusterlabeltfidf'].apply(lambda x: 1 if x ==1 else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pVGwDr83fV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1= pd.concat([X, bow], axis=1)\n",
        "X2= X.drop(title2vec_fts, axis=1)\n",
        "X3= X2.drop(text2vec_fts, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZSMw6kM3g4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,  stratify=y, test_size=0.33, random_state=42)\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, stratify=y, test_size=0.33, random_state=42)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, stratify=y, test_size=0.33, random_state=42)\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, stratify=y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLu5K4tu3ic4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "#imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "#from sklearn.preprocessing import Imputer\n",
        "\t\n",
        "im = SimpleImputer(strategy = 'median')\n",
        "X_train = im.fit_transform(X_train)\n",
        "X_test = im.transform(X_test)\n",
        "im1 = SimpleImputer(strategy = 'median')\n",
        "X1_train = im1.fit_transform(X1_train)\n",
        "X1_test = im1.transform(X1_test)\n",
        "im2 = SimpleImputer(strategy = 'median')\n",
        "X2_train = im2.fit_transform(X2_train)\n",
        "X2_test = im2.transform(X2_test)\n",
        "im3 = SimpleImputer(strategy = 'median')\n",
        "X3_train = im3.fit_transform(X3_train)\n",
        "X3_test = im3.transform(X3_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFhd-PAq3o-O",
        "colab_type": "text"
      },
      "source": [
        "# logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N7Qd5NE3loJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6sf2V7z3p8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "8d2f5059-e556-489a-f185-586bdd159453"
      },
      "source": [
        "lr = LogisticRegression(penalty='l2')\n",
        "lr.fit(X_train,y_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y_train, lr.predict_proba(X_train)[:,1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y_test, lr.predict_proba(X_test)[:,1])))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.66977296352612\n",
            "test auc with set set 0 features:0.6961166918948672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZKNMVve3rp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "48a1e1c2-1e65-4142-9579-af9cc2fd1d7e"
      },
      "source": [
        "lr1 = LogisticRegression(penalty='l2')\n",
        "lr1.fit(X1_train,y1_train)\n",
        "print('training auc with set set 1 features:{}'.format(roc_auc_score(y1_train, lr1.predict_proba(X1_train)[:,1])))\n",
        "print('test auc with set set 1 features:{}'.format(roc_auc_score(y1_test, lr1.predict_proba(X1_test)[:,1])))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 1 features:0.7918919171701677\n",
            "test auc with set set 1 features:0.675024081464153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp7Vjhl-3tb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "d146a3de-69c0-4571-f6fb-bce76e4a0f22"
      },
      "source": [
        "lr2 = LogisticRegression(penalty='l2')\n",
        "lr2.fit(X2_train,y2_train)\n",
        "print('training auc with set set 2 features:{}'.format(roc_auc_score(y2_train, lr2.predict_proba(X2_train)[:,1])))\n",
        "print('test auc with set set 2 features:{}'.format(roc_auc_score(y2_test, lr2.predict_proba(X2_test)[:,1])))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 2 features:0.6338869841507377\n",
            "test auc with set set 2 features:0.6821356818494565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDkZG45g3vEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "b1c45eec-77bd-4f26-9eda-4d8a7f183956"
      },
      "source": [
        "lr3 = LogisticRegression(penalty='l2')\n",
        "lr3.fit(X3_train,y3_train)\n",
        "print('training auc with set set 3 features:{}'.format(roc_auc_score(y3_train, lr3.predict_proba(X3_train)[:,1])))\n",
        "print('test auc with set set 3 features:{}'.format(roc_auc_score(y3_test, lr3.predict_proba(X3_test)[:,1])))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 3 features:0.6034537816697978\n",
            "test auc with set set 3 features:0.6497591853584699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn5Fel9g3yNt",
        "colab_type": "text"
      },
      "source": [
        "#SVC (too slow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_ko0ZAZ3w3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "c266462b-f6f9-481a-954a-87198c08838e"
      },
      "source": [
        "svc = SVC(probability=True, kernel='linear') \n",
        "svc.fit(X_train,y_train) \n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y_train, svc.predict_proba(X_train)[:,1]))) \n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y_test, svc.predict_proba(X_test)[:,1])))\n",
        "\n",
        "svc1 = SVC() svc1.fit(X1_train,y1_train) \n",
        "print('training auc with set set 1 features:{}'.format(roc_auc_score(y1_train, svc1.predict_proba(X1_train)[:,1]))) \n",
        "print('test auc with set set 1 features:{}'.format(roc_auc_score(y1_test, svc1.predict_proba(X1_test)[:,1])))\n",
        "\n",
        "svc2 = SVC() svc2.fit(X2_train,y2_train) \n",
        "print('training auc with set set 2 features:{}'.format(roc_auc_score(y2_train, svc2.predict_proba(X2_train)[:,1]))) \n",
        "print('test auc with set set 2 features:{}'.format(roc_auc_score(y2_test, svc2.predict_proba(X2_test)[:,1])))\n",
        "\n",
        "svc3 = SVC() svc3.fit(X3_train,y3_train) \n",
        "print('training auc with set set 3 features:{}'.format(roc_auc_score(y3_train, svc3.predict_proba(X3_train)[:,1]))) \n",
        "print('test auc with set set 3 features:{}'.format(roc_auc_score(y3_test, svc3.predict_proba(X3_test)[:,1])))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-83-526de08a64ff>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    svc1 = SVC() svc1.fit(X1_train,y1_train)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftUDVKtP35X9",
        "colab_type": "text"
      },
      "source": [
        "#Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nbX2HuA337k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "78f21999-ff44-4042-a61c-ed33bfef3e01"
      },
      "source": [
        "rf = RandomForestClassifier(max_depth=2, n_estimators=100)\n",
        "rf.fit(X_train,y_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y_train, rf.predict_proba(X_train)[:,1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.7901789889715215\n",
            "test auc with set set 0 features:0.6741103619100042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5RpM5j037lY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "74d9ed12-23a9-40fe-8e60-7d449f21c3e7"
      },
      "source": [
        "rf1 = RandomForestClassifier(max_depth=2, n_estimators=100)\n",
        "rf1.fit(X1_train,y1_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y1_train, rf1.predict_proba(X1_train)[:,1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y1_test, rf1.predict_proba(X1_test)[:,1])))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.799173866220575\n",
            "test auc with set set 0 features:0.6620476124948397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6_Dvsgz39IY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8a9dbcf0-1a43-4189-c41f-459ccff3f69e"
      },
      "source": [
        "rf2 = RandomForestClassifier(max_depth=2, n_estimators=100)\n",
        "rf2.fit(X2_train,y2_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y2_train, rf2.predict_proba(X2_train)[:, 1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y2_test, rf2.predict_proba(X2_test)[:, 1])))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.7746604206695117\n",
            "test auc with set set 0 features:0.6857245080500893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJem6qOC3-v-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dacfae98-b859-45a8-a19f-f95399d6e69d"
      },
      "source": [
        "rf3 = RandomForestClassifier(max_depth=2, n_estimators=100)\n",
        "rf3.fit(X3_train,y3_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y3_train, rf3.predict_proba(X3_train)[:, 1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y3_test, rf3.predict_proba(X3_test)[:, 1])))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.6719749180279679\n",
            "test auc with set set 0 features:0.6782743910829778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUvkUFQf4BvW",
        "colab_type": "text"
      },
      "source": [
        "# GBT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NANhpe4q4AoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os3Gkv3w4DGL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4249f823-e0e4-4ea8-ab57-6897e78c9996"
      },
      "source": [
        "gbt = GradientBoostingClassifier(max_depth=2, random_state=0)\n",
        "gbt.fit(X_train,y_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y_train, gbt.predict_proba(X_train)[:,1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y_test, gbt.predict_proba(X_test)[:, 1])))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.9505275070614864\n",
            "test auc with set set 0 features:0.657591853584698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNapTvwV4EvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e48529d4-48ca-485f-8c97-1e00893b124b"
      },
      "source": [
        "gbt1 = GradientBoostingClassifier(max_depth=2, random_state=0)\n",
        "gbt1.fit(X1_train,y1_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y1_train, gbt1.predict_proba(X1_train)[:,1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y1_test, gbt1.predict_proba(X1_test)[:,1])))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.9272232658940228\n",
            "test auc with set set 0 features:0.6752359983486996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obVdAheo4GP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dd147b59-d678-45ff-e145-89f86fd187e6"
      },
      "source": [
        "gbt2 = GradientBoostingClassifier(max_depth=2, random_state=0)\n",
        "gbt2.fit(X2_train,y2_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y2_train, gbt2.predict_proba(X2_train)[:, 1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y2_test, gbt2.predict_proba(X2_test)[:, 1])))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.9366209885813694\n",
            "test auc with set set 0 features:0.6711765515343332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ioc3noG84H23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fe1e06c2-8c9b-4fc7-ea42-8f81a79fd010"
      },
      "source": [
        "gbt3 = GradientBoostingClassifier(max_depth=2, random_state=0)\n",
        "gbt3.fit(X3_train,y3_train)\n",
        "print('training auc with set set 0 features:{}'.format(roc_auc_score(y3_train, gbt3.predict_proba(X3_train)[:, 1])))\n",
        "print('test auc with set set 0 features:{}'.format(roc_auc_score(y3_test, gbt3.predict_proba(X3_test)[:, 1])))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training auc with set set 0 features:0.750381467239246\n",
            "test auc with set set 0 features:0.6385826338241365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orbetp754Ky2",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S69Tu8lW4Js9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tstdf = pd.read_csv('/content/drive/My Drive/Food_Safety_Amazon/public_test_features.csv', sep=None, header=0, index_col=False, parse_dates=['Timestamp'],engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjPU-ThU4Vzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TextSentimentScores, TextIsOverallNeg = get_sentiment_scores_of_column(tstdf, 'Review Text')\n",
        "TitleSentimentScores, TitleIsOverallNeg = get_sentiment_scores_of_column(tstdf , 'Review Title')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJTWBdWP4XCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tstdf['missingorigin'] = tstdf['@product.countryOfOrigin'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
        "tstdf['Product Width'].fillna(-1, inplace=True)\n",
        "tstdf['Product Height'].fillna(-1, inplace=True)\n",
        "tstdf['Product Length'].fillna(-1, inplace=True)\n",
        "tstdf['missingwd'] = tstdf.apply(lambda x: 1 if x['Product Width']+x['Product Length']+x['Product Height']==-1 else 0, axis=1)\n",
        "tstdf['timezero'] = pd.Timestamp('20170101')\n",
        "tstdf['timedif'] = (tstdf['Timestamp'] - tstdf['timezero']).apply(lambda x: x.days)\n",
        "#df['timedif'].head(5)\n",
        "tstdf['volumn'] = tstdf['Product Width'] * tstdf['Product Length'] * tstdf['Product Height']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3-nXtP34Z9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6b2cab56-18dc-469f-9eca-742ec0af803e"
      },
      "source": [
        "tstdf['text2vec'] = tstdf['Review Text'].apply(word_vector)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MxpIDK54bFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster1=np.mean(df2['text2vec'].loc[X['clusterlabelw2v']==1],axis=0)\n",
        "cluster0=np.mean(df2['text2vec'].loc[X['clusterlabelw2v']==0],axis=0)\n",
        "def w2vcluster(v):\n",
        "    #print(v)\n",
        "    if isinstance(v, np.ndarray):\n",
        "        sim1 = cosine_similarity(np.reshape(cluster1,(1,-1)), np.reshape(v,(1, -1)))\n",
        "        sim0 = cosine_similarity(np.reshape(cluster0,(1,-1)), np.reshape(v,(1, -1)))\n",
        "        return 1 if sim1 > sim0 else 0\n",
        "    return 1\n",
        "tstdf['clusterlabelw2v'] = tstdf['text2vec'].apply(w2vcluster)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqUx_OFs4ebm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a394aed6-f240-456f-8253-4df092a31f77"
      },
      "source": [
        "text_split = tstdf['text2vec'].apply(lambda x: pd.Series([x[i] if not isinstance(x,np.float64) else np.nan for i in range(300)]))\n",
        "text_split.rename(columns={i:'text' + str(i+1) for i in range(300)},inplace=True)\n",
        "tstdf1 = pd.concat([tstdf, text_split], axis=1)\n",
        "tstdf1['title2vec'] = tstdf1['Review Title'].apply(word_vector)\n",
        "title_split = tstdf1['title2vec'].apply(lambda x: pd.Series([x[i] if not isinstance(x,np.float64) else np.nan for i in range(300)]))\n",
        "title_split.rename(columns={i:'title' + str(i+1) for i in range(300)},inplace=True)\n",
        "tstdf2 = pd.concat([tstdf1, title_split], axis=1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VosNFCUP4gve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfcluster1=np.mean(df2['text2vec'].loc[X['clusterlabeltfidf']==1],axis=0)\n",
        "tfcluster0=np.mean(df2['text2vec'].loc[X['clusterlabeltfidf']==0],axis=0)\n",
        "def tfidfcluster(v):\n",
        "    #print(v)\n",
        "    if isinstance(v, np.ndarray):\n",
        "        sim1 = cosine_similarity(np.reshape(tfcluster1,(1,-1)), np.reshape(v,(1, -1)))\n",
        "        sim0 = cosine_similarity(np.reshape(tfcluster0,(1,-1)), np.reshape(v,(1, -1)))\n",
        "        return 1 if sim1 > sim0 else 0\n",
        "    return 1\n",
        "tstdf2['clusterlabeltfidf'] = tstdf2['text2vec'].apply(tfidfcluster)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH4p5Lte4j7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tstID = tstdf2['ID']\t\n",
        "tstX = tstdf2.drop(['ID','Product ASIN','Review Text', 'Review Title', '@product.brand','@product.countryOfOrigin', 'Timestamp', 'Product Title (Analyzed)','text2vec','title2vec','timezero'], axis=1)\n",
        "\n",
        "#tstX1= tstX.drop(prod2vec_fts, axis=1)\n",
        "tstX2= tstX.drop(title2vec_fts, axis=1)\n",
        "tstX3= tstX2.drop(text2vec_fts, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR0o1-Qd4mPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tstX = im.transform(tstX)\n",
        "tstX2 = im2.transform(tstX2)\n",
        "tstX3 = im3.transform(tstX3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUOLy3mq4ngo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tstPred= gbt2.predict_proba(tstX2)[:, 1]\n",
        "results = ['ID,Food Safety Issue']\n",
        "for i in range(len(tstID)):\n",
        "    results.append(str(tstID[i]) + ',' + str(tstPred[i]))\n",
        "with open('test_scores_gbt2', 'w') as f:\n",
        "    for row in results:\n",
        "        f.write(\"%s\\n\" % row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGzKs6zY4qAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}